---
title: Ingestion Architecture - Plaintext Files
description: Describes the innermost layer of the ingestion pipeline, handling raw text or text outputs from other processors.
version: 1.0
date: 2025-04-13
---

# Ingestion Architecture: Plaintext Files

## 1. Role and Overview

The Plaintext File processor is the universal endpoint for textual content within the ingestion pipeline ([ARCHITECTURE_PROCESSING_INGESTION.md](../ARCHITECTURE_PROCESSING_INGESTION.md)). It receives textual data from various sources:

*   Naturally text-based files (e.g., `.txt`, `.md`, `.csv`, `.json`, `.xml`, source code files).
*   The textual output streams generated by other processors (e.g., LLM-generated image descriptions, audio transcriptions, text extracted from PDF/Office documents, raw XML from Office files).

Its core responsibility is to **convert the incoming textual data into a canonical, structured ephemeral Markdown representation**, and then ensure the **faithful and complete consumption** of this final Markdown output by downstream Persona processors.

## 2. Processing Steps

1.  **Receive Text Input:** Accepts input as:
    *   A single text stream or string with format hints (e.g., `source=xml`).
    *   **A bundle of multiple related text streams/strings** (e.g., XML components + LLM descriptions from an unpacked file collection) along with a **synthesis instruction** (e.g., "Synthesize a coherent Markdown document from these components representing the original source artifact").
2.  **Convert/Synthesize to Structured Markdown:**
    *   **Single Input:** If receiving a single input, convert it to Markdown as previously described (e.g., using libraries or LLM for complex formatting).
    *   **Bundle Input (Synthesis):** If receiving a bundle and a synthesis instruction:
        *   Construct a large prompt for the configured LLM (e.g., Gemini).
        *   Include the synthesis instruction, all provided textual components (XMLs, descriptions, etc.), and any relevant context (original container filename, etc.).
        *   Invoke the LLM, relying on its large context window and common-sense reasoning to interpret the relationships between the components (e.g., OOXML structure) and generate **one single, coherent, well-structured Markdown document** representing the original artifact.
3.  **Minimal Cleanup (Optional):** Perform final normalization on the generated/synthesized Markdown.
4.  **Return Ephemeral Markdown:** Provides the generated, canonical Markdown content (as a string or stream) to the next stage in the processing pipeline (typically a Persona processor).
5.  **Provide Context for Metadata:** Contributes information *relevant* to the final `ArtifactMetadata` record (e.g., confirming successful text processing, potentially identifying a title), but does not perform the final metadata update or link to persisted content (as there is none).

## 3. Key Principles

*   **Canonical Format = Markdown:** This processor's output is *always* structured Markdown.
*   **Ephemeral Output:** The generated Markdown is transient and consumed immediately by downstream Persona processors.
*   **No Chunking:** The final ephemeral Markdown output is passed *whole* to Personas.
*   **No Embedding:** Vector embeddings are not generated here.
*   **No Semantic Interpretation:** While it restructures text into Markdown, it does not analyze the meaning or extract entities beyond what's needed for formatting.
*   **Idempotency:** Given the same input text and format hint, it should consistently produce the same Markdown output. **Note on Idempotency:** The system determines whether an artifact needs processing based on its *source* identifiers (`sourceIdentifier`, possibly source hash/timestamp) and context (e.g., Persona version), *not* by hashing the variable Markdown output of the LLM. Processing the same source may yield slightly different Markdown, which is acceptable.

This processor ensures that all ingested textual information, regardless of its original form, is normalized into a consistent, high-quality Markdown format, providing a standardized foundation for the downstream retrieval and salient snippet extraction process.
